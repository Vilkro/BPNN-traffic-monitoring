{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and load dataset"
      ],
      "metadata": {
        "id": "6024vO2L1YRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL7y_oBG9BtC",
        "outputId": "8ed12968-631a-4785-b1d3-da493a041ce1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/CIC-IDS/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/MachineLearningCSV/MachineLearningCVE\"\n",
        "\n",
        "csv_files = [\n",
        "    \"Monday-WorkingHours.pcap_ISCX.csv\",\n",
        "    \"Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
        "    \"Wednesday-workingHours.pcap_ISCX.csv\",\n",
        "    \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
        "    \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
        "    \"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
        "    \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
        "    \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "for f in csv_files:\n",
        "    df_part = pd.read_csv(os.path.join(base_path, f))\n",
        "    df_part[\"SourceFile\"] = f\n",
        "    dfs.append(df_part)\n",
        "\n",
        "df_all = pd.concat(dfs, ignore_index=True)\n",
        "df_all.columns = df_all.columns.str.strip()\n",
        "\n",
        "print(\"Full dataset shape:\", df_all.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6hjIEmb1XlX",
        "outputId": "558a8394-982a-4be1-e2e3-aca6d955c216"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset shape: (2830743, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop columns"
      ],
      "metadata": {
        "id": "jtR3mAxN1ox4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop id columns\n",
        "drop_cols = [\n",
        "    'Timestamp', 'Flow ID', 'Src IP', 'Dst IP',\n",
        "    'Src Port', 'Dst Port', 'Protocol'\n",
        "]\n",
        "for col in drop_cols:\n",
        "    if col in df_all.columns:\n",
        "        df_all.drop(columns=[col], inplace=True)\n",
        "\n",
        "# remove rows without label\n",
        "df_all = df_all.dropna(subset=[\"Label\"])\n",
        "\n",
        "mask_mon_thu = df_all[\"SourceFile\"].str.contains(\"Monday|Tuesday|Wednesday|Thursday\", case=False, regex=True)\n",
        "mask_fri     = df_all[\"SourceFile\"].str.contains(\"Friday\", case=False, regex=True)\n",
        "\n",
        "df_mon_thu = df_all[mask_mon_thu].copy()\n",
        "df_fri     = df_all[mask_fri].copy()\n",
        "\n",
        "print(\"Mon–Thu raw shape:\", df_mon_thu.shape)\n",
        "print(\"Friday raw shape:\", df_fri.shape)"
      ],
      "metadata": {
        "id": "AUjE25_N1pML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b688eacf-7903-4f67-b986-ebfa2eb65ba5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon–Thu raw shape: (2127498, 80)\n",
            "Friday raw shape: (703245, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling"
      ],
      "metadata": {
        "id": "ed_d16eY1-96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# encode labels\n",
        "le = LabelEncoder()\n",
        "df_all[\"LabelEnc\"] = le.fit_transform(df_all[\"Label\"])\n",
        "print(\"Number of classes total:\", len(le.classes_))\n",
        "\n",
        "# attach encoded labels to subsets\n",
        "df_mon_thu[\"LabelEnc\"] = df_all.loc[df_mon_thu.index, \"LabelEnc\"]\n",
        "df_fri[\"LabelEnc\"]     = df_all.loc[df_fri.index, \"LabelEnc\"]\n",
        "\n",
        "# balanced sampling\n",
        "def balanced_sample(df, label_col, n_per_class=100000, random_state=42):\n",
        "    groups = []\n",
        "    for lab, g in df.groupby(label_col):\n",
        "        take = min(len(g), n_per_class)\n",
        "        groups.append(g.sample(n=take, random_state=random_state))\n",
        "    return pd.concat(groups, ignore_index=True)\n",
        "\n",
        "df_mon_thu_bal = balanced_sample(df_mon_thu, \"LabelEnc\", n_per_class=100000)\n",
        "df_fri_bal     = balanced_sample(df_fri, \"LabelEnc\", n_per_class=100000)\n",
        "\n",
        "print(\"Mon–Thu balanced shape:\", df_mon_thu_bal.shape)\n",
        "print(\"Friday balanced shape:\", df_fri_bal.shape)\n",
        "print(\"Mon–Thu class counts:\\n\", df_mon_thu_bal[\"LabelEnc\"].value_counts())\n",
        "print(\"Friday class counts:\\n\", df_fri_bal[\"LabelEnc\"].value_counts())"
      ],
      "metadata": {
        "id": "hxvUv16V192n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fcdf6d-3d20-4bc0-c3c0-99e68725e533"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes total: 15\n",
            "Mon–Thu balanced shape: (237650, 81)\n",
            "Friday balanced shape: (301966, 81)\n",
            "Mon–Thu class counts:\n",
            " LabelEnc\n",
            "0     100000\n",
            "4     100000\n",
            "3      10293\n",
            "7       7938\n",
            "11      5897\n",
            "6       5796\n",
            "5       5499\n",
            "12      1507\n",
            "14       652\n",
            "9         36\n",
            "13        21\n",
            "8         11\n",
            "Name: count, dtype: int64\n",
            "Friday class counts:\n",
            " LabelEnc\n",
            "0     100000\n",
            "2     100000\n",
            "10    100000\n",
            "1       1966\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df_mon_thu_bal.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "def prepare_X_y(df, num_cols, label_col=\"LabelEnc\"):\n",
        "    X = df[num_cols].copy()\n",
        "\n",
        "    if label_col in X.columns:\n",
        "        X = X.drop(columns=[label_col])\n",
        "\n",
        "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    X = X.fillna(X.median(numeric_only=True))\n",
        "\n",
        "    X = X.astype(\"float32\")\n",
        "    y = df[label_col].to_numpy()\n",
        "    return X, y\n",
        "\n",
        "X_mon_thu, y_mon_thu = prepare_X_y(df_mon_thu_bal, num_cols)\n",
        "X_fri,     y_fri     = prepare_X_y(df_fri_bal, num_cols)\n",
        "\n",
        "print(\"Mon–Thu X shape:\", X_mon_thu.shape)\n",
        "print(\"Friday X shape:\", X_fri.shape)\n",
        "\n",
        "import numpy as np\n",
        "print(\"Any NaN Mon–Thu:\", np.isnan(X_mon_thu.to_numpy()).any())\n",
        "print(\"Any NaN Friday :\", np.isnan(X_fri.to_numpy()).any())\n",
        "print(\"Any inf Mon–Thu:\", np.isinf(X_mon_thu.to_numpy()).any())\n",
        "print(\"Any inf Friday :\", np.isinf(X_fri.to_numpy()).any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D7aDsRnZ-Ff",
        "outputId": "31a65e3d-2b37-4021-907b-397f651ecd5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon–Thu X shape: (237650, 78)\n",
            "Friday X shape: (301966, 78)\n",
            "Any NaN Mon–Thu: False\n",
            "Any NaN Friday : False\n",
            "Any inf Mon–Thu: False\n",
            "Any inf Friday : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define phase 1\n",
        "train on Monday–Thursday, test on all Friday"
      ],
      "metadata": {
        "id": "bc1voFL_2JQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Masks based on SourceFile\n",
        "# mask_mon_thu = df_all[\"SourceFile\"].str.contains(\"Monday|Tuesday|Wednesday|Thursday\", case=False, regex=True)\n",
        "# mask_fri     = df_all[\"SourceFile\"].str.contains(\"Friday\", case=False, regex=True)\n",
        "\n",
        "# X_mon_thu = X_all[mask_mon_thu].to_numpy()\n",
        "# y_mon_thu = y_all_enc[mask_mon_thu]\n",
        "\n",
        "# X_fri_all = X_all[mask_fri].to_numpy()\n",
        "# y_fri_all = y_all_enc[mask_fri]\n",
        "\n",
        "# print(\"Mon–Thu shape:\", X_mon_thu.shape, \" Friday shape:\", X_fri_all.shape)"
      ],
      "metadata": {
        "id": "OKPb4_k42M0V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/test split"
      ],
      "metadata": {
        "id": "v4Ga8G3Dl0BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_fri_train, X_fri_test, y_fri_train, y_fri_test = train_test_split(\n",
        "    X_fri,\n",
        "    y_fri,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_fri\n",
        ")\n",
        "\n",
        "print(\"Friday train:\", X_fri_train.shape, \" Friday test:\", X_fri_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTRHJvWyl0VK",
        "outputId": "5b34359b-03b8-41a7-e559-3d21de680f08"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friday train: (211376, 78)  Friday test: (90590, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "XG46j2VgmJTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_mon_thu)\n",
        "\n",
        "X_mon_thu_scaled   = scaler.transform(X_mon_thu)\n",
        "X_fri_scaled       = scaler.transform(X_fri)\n",
        "X_fri_train_scaled = scaler.transform(X_fri_train)\n",
        "X_fri_test_scaled  = scaler.transform(X_fri_test)"
      ],
      "metadata": {
        "id": "H9gUvpdbmKw0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining BPNN"
      ],
      "metadata": {
        "id": "q6hYSlj_2W6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "input_dim = X_mon_thu_scaled.shape[1]\n",
        "print(\"Input dim:\", input_dim, \"Num classes:\", num_classes)\n",
        "\n",
        "def build_bpnn_stronger(input_dim, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "U0jpnu3W2bFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ac62c1-b54a-426e-a126-2dec1dc8178d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dim: 78 Num classes: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1"
      ],
      "metadata": {
        "id": "OoB0dWqE2htD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# Phase 1 training\n",
        "y_mon_thu_cat = to_categorical(y_mon_thu, num_classes=num_classes)\n",
        "\n",
        "model_p1 = build_bpnn_stronger(input_dim, num_classes)\n",
        "\n",
        "history_p1 = model_p1.fit(\n",
        "    X_mon_thu_scaled,\n",
        "    y_mon_thu_cat,\n",
        "    epochs=15,             # moderate training\n",
        "    batch_size=512,        # smaller batch to reduce RAM spikes\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Phase 1 evaluation on all Friday\n",
        "y_fri_pred_proba_p1 = model_p1.predict(X_fri_scaled, verbose=0)\n",
        "y_fri_pred_p1 = np.argmax(y_fri_pred_proba_p1, axis=1)\n",
        "\n",
        "print(\"\\n[Phase 1] Friday evaluation (balanced subset):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_fri, y_fri_pred_p1))\n",
        "print(\"F1-macro   :\", f1_score(y_fri, y_fri_pred_p1, average=\"macro\"))\n",
        "print(\"F1-weighted:\", f1_score(y_fri, y_fri_pred_p1, average=\"weighted\"))\n",
        "\n",
        "labels_fri = np.unique(y_fri)\n",
        "target_names_fri = le.inverse_transform(labels_fri)\n",
        "\n",
        "print(\"\\n[Phase 1] Classification report (Friday):\")\n",
        "print(classification_report(\n",
        "    y_fri,\n",
        "    y_fri_pred_p1,\n",
        "    labels=labels_fri,\n",
        "    target_names=target_names_fri,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "id": "4EMNgfK82hGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da04223f-3347-4fe4-fa88-9b15c414f8a9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8849 - loss: 0.4032 - val_accuracy: 0.4232 - val_loss: 14.9921\n",
            "Epoch 2/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0594 - val_accuracy: 0.4238 - val_loss: 20.1936\n",
            "Epoch 3/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9856 - loss: 0.0441 - val_accuracy: 0.4239 - val_loss: 25.5033\n",
            "Epoch 4/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 0.0397 - val_accuracy: 0.4236 - val_loss: 29.5741\n",
            "Epoch 5/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9876 - loss: 0.0363 - val_accuracy: 0.4238 - val_loss: 32.9380\n",
            "Epoch 6/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0352 - val_accuracy: 0.4238 - val_loss: 38.6255\n",
            "Epoch 7/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0347 - val_accuracy: 0.4238 - val_loss: 40.5400\n",
            "Epoch 8/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9884 - loss: 0.0338 - val_accuracy: 0.4241 - val_loss: 44.0144\n",
            "Epoch 9/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9887 - loss: 0.0329 - val_accuracy: 0.4238 - val_loss: 49.2605\n",
            "Epoch 10/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9887 - loss: 0.0319 - val_accuracy: 0.4237 - val_loss: 50.4720\n",
            "Epoch 11/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9888 - loss: 0.0315 - val_accuracy: 0.4238 - val_loss: 53.0075\n",
            "Epoch 12/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0304 - val_accuracy: 0.4238 - val_loss: 56.1244\n",
            "Epoch 13/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0283 - val_accuracy: 0.4243 - val_loss: 59.1735\n",
            "Epoch 14/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0317 - val_accuracy: 0.4241 - val_loss: 64.1072\n",
            "Epoch 15/15\n",
            "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9896 - loss: 0.0298 - val_accuracy: 0.4241 - val_loss: 67.5273\n",
            "\n",
            "[Phase 1] Friday evaluation (balanced subset):\n",
            "Accuracy: 0.32747064239020285\n",
            "F1-macro   : 0.09778298575059084\n",
            "F1-weighted: 0.19429270663039713\n",
            "\n",
            "[Phase 1] Classification report (Friday):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.42      0.99      0.59    100000\n",
            "         Bot       0.00      0.00      0.00      1966\n",
            "        DDoS       0.00      0.00      0.00    100000\n",
            "    PortScan       0.00      0.00      0.00    100000\n",
            "\n",
            "   micro avg       0.42      0.33      0.37    301966\n",
            "   macro avg       0.10      0.25      0.15    301966\n",
            "weighted avg       0.14      0.33      0.19    301966\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2"
      ],
      "metadata": {
        "id": "ILnLIfRKd9E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Phase 2: Adaptation with Mon–Thu + Friday-train ===\")\n",
        "\n",
        "# combine Mon–Thu and Friday-train for adaptation\n",
        "X_phase2_train = np.vstack([X_mon_thu_scaled, X_fri_train_scaled])\n",
        "y_phase2_train = np.concatenate([y_mon_thu, y_fri_train])\n",
        "y_phase2_cat   = to_categorical(y_phase2_train, num_classes=num_classes)\n",
        "\n",
        "model_p2 = build_bpnn_stronger(input_dim, num_classes)\n",
        "\n",
        "history_p2 = model_p2.fit(\n",
        "    X_phase2_train,\n",
        "    y_phase2_cat,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# evaluate on Friday-test\n",
        "y_fri_test_pred_proba = model_p2.predict(X_fri_test_scaled, verbose=0)\n",
        "y_fri_test_pred = np.argmax(y_fri_test_pred_proba, axis=1)\n",
        "\n",
        "print(\"\\n[Phase 2] Friday-test evaluation (after adaptation):\")\n",
        "print(\"Accuracy:\", accuracy_score(y_fri_test, y_fri_test_pred))\n",
        "print(\"F1-macro   :\", f1_score(y_fri_test, y_fri_test_pred, average=\"macro\"))\n",
        "print(\"F1-weighted:\", f1_score(y_fri_test, y_fri_test_pred, average=\"weighted\"))\n",
        "\n",
        "labels_fri_test = np.unique(y_fri_test)\n",
        "target_names_fri_test = le.inverse_transform(labels_fri_test)\n",
        "\n",
        "print(\"\\n[Phase 2] Classification report (Friday-test):\")\n",
        "print(classification_report(\n",
        "    y_fri_test,\n",
        "    y_fri_test_pred,\n",
        "    labels=labels_fri_test,\n",
        "    target_names=target_names_fri_test,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGJbIVy-d_Ae",
        "outputId": "1b8db98d-acbb-45ab-d823-9038d4c5ea58"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Phase 2: Adaptation with Mon–Thu + Friday-train ===\n",
            "Epoch 1/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.8040 - loss: 0.6566 - val_accuracy: 0.9749 - val_loss: 0.0837\n",
            "Epoch 2/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9586 - loss: 0.1428 - val_accuracy: 0.9759 - val_loss: 0.0787\n",
            "Epoch 3/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9665 - loss: 0.1139 - val_accuracy: 0.9843 - val_loss: 0.0558\n",
            "Epoch 4/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9706 - loss: 0.0977 - val_accuracy: 0.9827 - val_loss: 0.0544\n",
            "Epoch 5/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9734 - loss: 0.0878 - val_accuracy: 0.9868 - val_loss: 0.0587\n",
            "Epoch 6/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9744 - loss: 0.0839 - val_accuracy: 0.9849 - val_loss: 0.0527\n",
            "Epoch 7/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9761 - loss: 0.0787 - val_accuracy: 0.9901 - val_loss: 0.0473\n",
            "Epoch 8/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0778 - val_accuracy: 0.9899 - val_loss: 0.0441\n",
            "Epoch 9/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9777 - loss: 0.0731 - val_accuracy: 0.9904 - val_loss: 0.0418\n",
            "Epoch 10/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9780 - loss: 0.0726 - val_accuracy: 0.9905 - val_loss: 0.0447\n",
            "Epoch 11/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9785 - loss: 0.0695 - val_accuracy: 0.9910 - val_loss: 0.0377\n",
            "Epoch 12/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9785 - loss: 0.0717 - val_accuracy: 0.9906 - val_loss: 0.0396\n",
            "Epoch 13/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9791 - loss: 0.0673 - val_accuracy: 0.9907 - val_loss: 0.0476\n",
            "Epoch 14/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9793 - loss: 0.0658 - val_accuracy: 0.9908 - val_loss: 0.0359\n",
            "Epoch 15/15\n",
            "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9796 - loss: 0.0651 - val_accuracy: 0.9908 - val_loss: 0.0391\n",
            "\n",
            "[Phase 2] Friday-test evaluation (after adaptation):\n",
            "Accuracy: 0.9900651286013908\n",
            "F1-macro   : 0.3352962088958064\n",
            "F1-weighted: 0.9927406110110291\n",
            "\n",
            "[Phase 2] Classification report (Friday-test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      BENIGN       0.99      0.98      0.99     30000\n",
            "         Bot       0.85      0.60      0.70       590\n",
            "        DDoS       1.00      1.00      1.00     30000\n",
            "    PortScan       1.00      1.00      1.00     30000\n",
            "\n",
            "   micro avg       1.00      0.99      0.99     90590\n",
            "   macro avg       0.96      0.89      0.92     90590\n",
            "weighted avg       1.00      0.99      0.99     90590\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
